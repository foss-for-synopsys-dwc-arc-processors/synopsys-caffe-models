name: "ResNet"
layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param { shape: { dim: 1 dim: 3 dim: 224 dim: 224 } }
}

layer {
  name: "bn_data"
  type: "BatchNorm"
  bottom: "data"
  top: "bn0"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
  }
}

layer {
  name: "scale_bn_data"
  bottom: "bn0"
  top: "scale0"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}

layer {
  name: "conv0"
  type: "Convolution"
  bottom: "scale0"
  top: "conv0"
  convolution_param {
    num_output: 64
    kernel_size: 7
    stride: 2
    pad: 3
    bias_term: false
  }
}

layer {
  name: "bn0"
  type: "BatchNorm"
  bottom: "conv0"
  top: "conv0"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_bn0"
  bottom: "conv0"
  top: "conv0"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "relu0"
  type: "ReLU"
  bottom: "conv0"
  top: "conv0"
  }

layer {
  name: "pooling0"
  type: "Pooling"
  bottom: "conv0"
  top: "pooling0"
  pooling_param {
     pool: MAX
     kernel_size: 3
     stride: 2
    }
  }

layer {
  name: "stage1_unit1_conv1"
  type: "Convolution"
  bottom: "pooling0"
  top: "stage1_unit1_conv1"
  convolution_param { 
     num_output: 128
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage1_unit1_bn1"
  type: "BatchNorm"
  bottom: "stage1_unit1_conv1"
  top: "stage1_unit1_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage1_unit1_bn1"
  bottom: "stage1_unit1_conv1"
  top: "stage1_unit1_conv1"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage1_unit1_relu1"
  type: "ReLU"
  bottom: "stage1_unit1_conv1"
  top: "stage1_unit1_conv1"
  }

layer {
  name: "stage1_unit1_conv2"
  type: "Convolution"
  bottom: "stage1_unit1_conv1"
  top: "stage1_unit1_conv2"
  convolution_param { 
     num_output: 128
     kernel_size: 3
     stride: 1
     group: 32
     pad: 1
     bias_term: false
    }
  }

layer {
  name: "stage1_unit1_bn2"
  type: "BatchNorm"
  bottom: "stage1_unit1_conv2"
  top: "stage1_unit1_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage1_unit1_bn2"
  bottom: "stage1_unit1_conv2"
  top: "stage1_unit1_conv2"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage1_unit1_relu2"
  type: "ReLU"
  bottom: "stage1_unit1_conv2"
  top: "stage1_unit1_conv2"
  }

layer {
  name: "stage1_unit1_conv3"
  type: "Convolution"
  bottom: "stage1_unit1_conv2"
  top: "stage1_unit1_conv3"
  convolution_param { 
     num_output: 256
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage1_unit1_bn3"
  type: "BatchNorm"
  bottom: "stage1_unit1_conv3"
  top: "stage1_unit1_conv3"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage1_unit1_bn3"
  bottom: "stage1_unit1_conv3"
  top: "stage1_unit1_conv3"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage1_unit1_sc"
  type: "Convolution"
  bottom: "pooling0"
  top: "stage1_unit1_sc"
  convolution_param { 
     num_output: 256
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage1_unit1_sc_bn"
  type: "BatchNorm"
  bottom: "stage1_unit1_sc"
  top: "stage1_unit1_sc"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage1_unit1_sc_bn"
  bottom: "stage1_unit1_sc"
  top: "stage1_unit1_sc"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage1_unit1_plus"
  type: "Eltwise"
  bottom: "stage1_unit1_sc"
  bottom: "stage1_unit1_conv3"
  top: "stage1_unit1_plus"
  eltwise_param {
     operation: SUM
    }
  }

layer {
  name: "stage1_unit1_relu"
  type: "ReLU"
  bottom: "stage1_unit1_plus"
  top: "stage1_unit1_plus"
  }

layer {
  name: "stage1_unit2_conv1"
  type: "Convolution"
  bottom: "stage1_unit1_plus"
  top: "stage1_unit2_conv1"
  convolution_param { 
     num_output: 128
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage1_unit2_bn1"
  type: "BatchNorm"
  bottom: "stage1_unit2_conv1"
  top: "stage1_unit2_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage1_unit2_bn1"
  bottom: "stage1_unit2_conv1"
  top: "stage1_unit2_conv1"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage1_unit2_relu1"
  type: "ReLU"
  bottom: "stage1_unit2_conv1"
  top: "stage1_unit2_conv1"
  }

layer {
  name: "stage1_unit2_conv2"
  type: "Convolution"
  bottom: "stage1_unit2_conv1"
  top: "stage1_unit2_conv2"
  convolution_param { 
     num_output: 128
     kernel_size: 3
     stride: 1
     group: 32
     pad: 1
     bias_term: false
    }
  }

layer {
  name: "stage1_unit2_bn2"
  type: "BatchNorm"
  bottom: "stage1_unit2_conv2"
  top: "stage1_unit2_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage1_unit2_bn2"
  bottom: "stage1_unit2_conv2"
  top: "stage1_unit2_conv2"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage1_unit2_relu2"
  type: "ReLU"
  bottom: "stage1_unit2_conv2"
  top: "stage1_unit2_conv2"
  }

layer {
  name: "stage1_unit2_conv3"
  type: "Convolution"
  bottom: "stage1_unit2_conv2"
  top: "stage1_unit2_conv3"
  convolution_param { 
     num_output: 256
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage1_unit2_bn3"
  type: "BatchNorm"
  bottom: "stage1_unit2_conv3"
  top: "stage1_unit2_conv3"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage1_unit2_bn3"
  bottom: "stage1_unit2_conv3"
  top: "stage1_unit2_conv3"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage1_unit2_plus"
  type: "Eltwise"
  bottom: "stage1_unit1_plus"
  bottom: "stage1_unit2_conv3"
  top: "stage1_unit2_plus"
  eltwise_param {
     operation: SUM
    }
  }

layer {
  name: "stage1_unit2_relu"
  type: "ReLU"
  bottom: "stage1_unit2_plus"
  top: "stage1_unit2_plus"
  }

layer {
  name: "stage1_unit3_conv1"
  type: "Convolution"
  bottom: "stage1_unit2_plus"
  top: "stage1_unit3_conv1"
  convolution_param { 
     num_output: 128
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage1_unit3_bn1"
  type: "BatchNorm"
  bottom: "stage1_unit3_conv1"
  top: "stage1_unit3_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage1_unit3_bn1"
  bottom: "stage1_unit3_conv1"
  top: "stage1_unit3_conv1"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage1_unit3_relu1"
  type: "ReLU"
  bottom: "stage1_unit3_conv1"
  top: "stage1_unit3_conv1"
  }

layer {
  name: "stage1_unit3_conv2"
  type: "Convolution"
  bottom: "stage1_unit3_conv1"
  top: "stage1_unit3_conv2"
  convolution_param { 
     num_output: 128
     kernel_size: 3
     stride: 1
     group: 32
     pad: 1
     bias_term: false
    }
  }

layer {
  name: "stage1_unit3_bn2"
  type: "BatchNorm"
  bottom: "stage1_unit3_conv2"
  top: "stage1_unit3_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage1_unit3_bn2"
  bottom: "stage1_unit3_conv2"
  top: "stage1_unit3_conv2"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage1_unit3_relu2"
  type: "ReLU"
  bottom: "stage1_unit3_conv2"
  top: "stage1_unit3_conv2"
  }

layer {
  name: "stage1_unit3_conv3"
  type: "Convolution"
  bottom: "stage1_unit3_conv2"
  top: "stage1_unit3_conv3"
  convolution_param { 
     num_output: 256
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage1_unit3_bn3"
  type: "BatchNorm"
  bottom: "stage1_unit3_conv3"
  top: "stage1_unit3_conv3"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage1_unit3_bn3"
  bottom: "stage1_unit3_conv3"
  top: "stage1_unit3_conv3"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage1_unit3_plus"
  type: "Eltwise"
  bottom: "stage1_unit2_plus"
  bottom: "stage1_unit3_conv3"
  top: "stage1_unit3_plus"
  eltwise_param {
     operation: SUM
    }
  }

layer {
  name: "stage1_unit3_relu"
  type: "ReLU"
  bottom: "stage1_unit3_plus"
  top: "stage1_unit3_plus"
  }

layer {
  name: "stage2_unit1_conv1"
  type: "Convolution"
  bottom: "stage1_unit3_plus"
  top: "stage2_unit1_conv1"
  convolution_param { 
     num_output: 256
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage2_unit1_bn1"
  type: "BatchNorm"
  bottom: "stage2_unit1_conv1"
  top: "stage2_unit1_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage2_unit1_bn1"
  bottom: "stage2_unit1_conv1"
  top: "stage2_unit1_conv1"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage2_unit1_relu1"
  type: "ReLU"
  bottom: "stage2_unit1_conv1"
  top: "stage2_unit1_conv1"
  }

layer {
  name: "stage2_unit1_conv2"
  type: "Convolution"
  bottom: "stage2_unit1_conv1"
  top: "stage2_unit1_conv2"
  convolution_param { 
     num_output: 256
     kernel_size: 3
     stride: 2
     group: 32
     pad: 1
     bias_term: false
    }
  }

layer {
  name: "stage2_unit1_bn2"
  type: "BatchNorm"
  bottom: "stage2_unit1_conv2"
  top: "stage2_unit1_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage2_unit1_bn2"
  bottom: "stage2_unit1_conv2"
  top: "stage2_unit1_conv2"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage2_unit1_relu2"
  type: "ReLU"
  bottom: "stage2_unit1_conv2"
  top: "stage2_unit1_conv2"
  }

layer {
  name: "stage2_unit1_conv3"
  type: "Convolution"
  bottom: "stage2_unit1_conv2"
  top: "stage2_unit1_conv3"
  convolution_param { 
     num_output: 512
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage2_unit1_bn3"
  type: "BatchNorm"
  bottom: "stage2_unit1_conv3"
  top: "stage2_unit1_conv3"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage2_unit1_bn3"
  bottom: "stage2_unit1_conv3"
  top: "stage2_unit1_conv3"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage2_unit1_sc"
  type: "Convolution"
  bottom: "stage1_unit3_plus"
  top: "stage2_unit1_sc"
  convolution_param { 
     num_output: 512
     kernel_size: 1
     stride: 2
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage2_unit1_sc_bn"
  type: "BatchNorm"
  bottom: "stage2_unit1_sc"
  top: "stage2_unit1_sc"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage2_unit1_sc_bn"
  bottom: "stage2_unit1_sc"
  top: "stage2_unit1_sc"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage2_unit1_plus"
  type: "Eltwise"
  bottom: "stage2_unit1_sc"
  bottom: "stage2_unit1_conv3"
  top: "stage2_unit1_plus"
  eltwise_param {
     operation: SUM
    }
  }

layer {
  name: "stage2_unit1_relu"
  type: "ReLU"
  bottom: "stage2_unit1_plus"
  top: "stage2_unit1_plus"
  }

layer {
  name: "stage2_unit2_conv1"
  type: "Convolution"
  bottom: "stage2_unit1_plus"
  top: "stage2_unit2_conv1"
  convolution_param { 
     num_output: 256
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage2_unit2_bn1"
  type: "BatchNorm"
  bottom: "stage2_unit2_conv1"
  top: "stage2_unit2_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage2_unit2_bn1"
  bottom: "stage2_unit2_conv1"
  top: "stage2_unit2_conv1"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage2_unit2_relu1"
  type: "ReLU"
  bottom: "stage2_unit2_conv1"
  top: "stage2_unit2_conv1"
  }

layer {
  name: "stage2_unit2_conv2"
  type: "Convolution"
  bottom: "stage2_unit2_conv1"
  top: "stage2_unit2_conv2"
  convolution_param { 
     num_output: 256
     kernel_size: 3
     stride: 1
     group: 32
     pad: 1
     bias_term: false
    }
  }

layer {
  name: "stage2_unit2_bn2"
  type: "BatchNorm"
  bottom: "stage2_unit2_conv2"
  top: "stage2_unit2_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage2_unit2_bn2"
  bottom: "stage2_unit2_conv2"
  top: "stage2_unit2_conv2"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage2_unit2_relu2"
  type: "ReLU"
  bottom: "stage2_unit2_conv2"
  top: "stage2_unit2_conv2"
  }

layer {
  name: "stage2_unit2_conv3"
  type: "Convolution"
  bottom: "stage2_unit2_conv2"
  top: "stage2_unit2_conv3"
  convolution_param { 
     num_output: 512
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage2_unit2_bn3"
  type: "BatchNorm"
  bottom: "stage2_unit2_conv3"
  top: "stage2_unit2_conv3"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage2_unit2_bn3"
  bottom: "stage2_unit2_conv3"
  top: "stage2_unit2_conv3"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage2_unit2_plus"
  type: "Eltwise"
  bottom: "stage2_unit1_plus"
  bottom: "stage2_unit2_conv3"
  top: "stage2_unit2_plus"
  eltwise_param {
     operation: SUM
    }
  }

layer {
  name: "stage2_unit2_relu"
  type: "ReLU"
  bottom: "stage2_unit2_plus"
  top: "stage2_unit2_plus"
  }

layer {
  name: "stage2_unit3_conv1"
  type: "Convolution"
  bottom: "stage2_unit2_plus"
  top: "stage2_unit3_conv1"
  convolution_param { 
     num_output: 256
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage2_unit3_bn1"
  type: "BatchNorm"
  bottom: "stage2_unit3_conv1"
  top: "stage2_unit3_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage2_unit3_bn1"
  bottom: "stage2_unit3_conv1"
  top: "stage2_unit3_conv1"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage2_unit3_relu1"
  type: "ReLU"
  bottom: "stage2_unit3_conv1"
  top: "stage2_unit3_conv1"
  }

layer {
  name: "stage2_unit3_conv2"
  type: "Convolution"
  bottom: "stage2_unit3_conv1"
  top: "stage2_unit3_conv2"
  convolution_param { 
     num_output: 256
     kernel_size: 3
     stride: 1
     group: 32
     pad: 1
     bias_term: false
    }
  }

layer {
  name: "stage2_unit3_bn2"
  type: "BatchNorm"
  bottom: "stage2_unit3_conv2"
  top: "stage2_unit3_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage2_unit3_bn2"
  bottom: "stage2_unit3_conv2"
  top: "stage2_unit3_conv2"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage2_unit3_relu2"
  type: "ReLU"
  bottom: "stage2_unit3_conv2"
  top: "stage2_unit3_conv2"
  }

layer {
  name: "stage2_unit3_conv3"
  type: "Convolution"
  bottom: "stage2_unit3_conv2"
  top: "stage2_unit3_conv3"
  convolution_param { 
     num_output: 512
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage2_unit3_bn3"
  type: "BatchNorm"
  bottom: "stage2_unit3_conv3"
  top: "stage2_unit3_conv3"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage2_unit3_bn3"
  bottom: "stage2_unit3_conv3"
  top: "stage2_unit3_conv3"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage2_unit3_plus"
  type: "Eltwise"
  bottom: "stage2_unit2_plus"
  bottom: "stage2_unit3_conv3"
  top: "stage2_unit3_plus"
  eltwise_param {
     operation: SUM
    }
  }

layer {
  name: "stage2_unit3_relu"
  type: "ReLU"
  bottom: "stage2_unit3_plus"
  top: "stage2_unit3_plus"
  }

layer {
  name: "stage2_unit4_conv1"
  type: "Convolution"
  bottom: "stage2_unit3_plus"
  top: "stage2_unit4_conv1"
  convolution_param { 
     num_output: 256
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage2_unit4_bn1"
  type: "BatchNorm"
  bottom: "stage2_unit4_conv1"
  top: "stage2_unit4_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage2_unit4_bn1"
  bottom: "stage2_unit4_conv1"
  top: "stage2_unit4_conv1"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage2_unit4_relu1"
  type: "ReLU"
  bottom: "stage2_unit4_conv1"
  top: "stage2_unit4_conv1"
  }

layer {
  name: "stage2_unit4_conv2"
  type: "Convolution"
  bottom: "stage2_unit4_conv1"
  top: "stage2_unit4_conv2"
  convolution_param { 
     num_output: 256
     kernel_size: 3
     stride: 1
     group: 32
     pad: 1
     bias_term: false
    }
  }

layer {
  name: "stage2_unit4_bn2"
  type: "BatchNorm"
  bottom: "stage2_unit4_conv2"
  top: "stage2_unit4_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage2_unit4_bn2"
  bottom: "stage2_unit4_conv2"
  top: "stage2_unit4_conv2"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage2_unit4_relu2"
  type: "ReLU"
  bottom: "stage2_unit4_conv2"
  top: "stage2_unit4_conv2"
  }

layer {
  name: "stage2_unit4_conv3"
  type: "Convolution"
  bottom: "stage2_unit4_conv2"
  top: "stage2_unit4_conv3"
  convolution_param { 
     num_output: 512
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage2_unit4_bn3"
  type: "BatchNorm"
  bottom: "stage2_unit4_conv3"
  top: "stage2_unit4_conv3"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage2_unit4_bn3"
  bottom: "stage2_unit4_conv3"
  top: "stage2_unit4_conv3"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage2_unit4_plus"
  type: "Eltwise"
  bottom: "stage2_unit3_plus"
  bottom: "stage2_unit4_conv3"
  top: "stage2_unit4_plus"
  eltwise_param {
     operation: SUM
    }
  }

layer {
  name: "stage2_unit4_relu"
  type: "ReLU"
  bottom: "stage2_unit4_plus"
  top: "stage2_unit4_plus"
  }

layer {
  name: "stage3_unit1_conv1"
  type: "Convolution"
  bottom: "stage2_unit4_plus"
  top: "stage3_unit1_conv1"
  convolution_param { 
     num_output: 512
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage3_unit1_bn1"
  type: "BatchNorm"
  bottom: "stage3_unit1_conv1"
  top: "stage3_unit1_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit1_bn1"
  bottom: "stage3_unit1_conv1"
  top: "stage3_unit1_conv1"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit1_relu1"
  type: "ReLU"
  bottom: "stage3_unit1_conv1"
  top: "stage3_unit1_conv1"
  }

layer {
  name: "stage3_unit1_conv2"
  type: "Convolution"
  bottom: "stage3_unit1_conv1"
  top: "stage3_unit1_conv2"
  convolution_param { 
     num_output: 512
     kernel_size: 3
     stride: 2
     group: 32
     pad: 1
     bias_term: false
    }
  }

layer {
  name: "stage3_unit1_bn2"
  type: "BatchNorm"
  bottom: "stage3_unit1_conv2"
  top: "stage3_unit1_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit1_bn2"
  bottom: "stage3_unit1_conv2"
  top: "stage3_unit1_conv2"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit1_relu2"
  type: "ReLU"
  bottom: "stage3_unit1_conv2"
  top: "stage3_unit1_conv2"
  }

layer {
  name: "stage3_unit1_conv3"
  type: "Convolution"
  bottom: "stage3_unit1_conv2"
  top: "stage3_unit1_conv3"
  convolution_param { 
     num_output: 1024
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage3_unit1_bn3"
  type: "BatchNorm"
  bottom: "stage3_unit1_conv3"
  top: "stage3_unit1_conv3"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit1_bn3"
  bottom: "stage3_unit1_conv3"
  top: "stage3_unit1_conv3"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit1_sc"
  type: "Convolution"
  bottom: "stage2_unit4_plus"
  top: "stage3_unit1_sc"
  convolution_param { 
     num_output: 1024
     kernel_size: 1
     stride: 2
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage3_unit1_sc_bn"
  type: "BatchNorm"
  bottom: "stage3_unit1_sc"
  top: "stage3_unit1_sc"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit1_sc_bn"
  bottom: "stage3_unit1_sc"
  top: "stage3_unit1_sc"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit1_plus"
  type: "Eltwise"
  bottom: "stage3_unit1_sc"
  bottom: "stage3_unit1_conv3"
  top: "stage3_unit1_plus"
  eltwise_param {
     operation: SUM
    }
  }

layer {
  name: "stage3_unit1_relu"
  type: "ReLU"
  bottom: "stage3_unit1_plus"
  top: "stage3_unit1_plus"
  }

layer {
  name: "stage3_unit2_conv1"
  type: "Convolution"
  bottom: "stage3_unit1_plus"
  top: "stage3_unit2_conv1"
  convolution_param { 
     num_output: 512
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage3_unit2_bn1"
  type: "BatchNorm"
  bottom: "stage3_unit2_conv1"
  top: "stage3_unit2_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit2_bn1"
  bottom: "stage3_unit2_conv1"
  top: "stage3_unit2_conv1"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit2_relu1"
  type: "ReLU"
  bottom: "stage3_unit2_conv1"
  top: "stage3_unit2_conv1"
  }

layer {
  name: "stage3_unit2_conv2"
  type: "Convolution"
  bottom: "stage3_unit2_conv1"
  top: "stage3_unit2_conv2"
  convolution_param { 
     num_output: 512
     kernel_size: 3
     stride: 1
     group: 32
     pad: 1
     bias_term: false
    }
  }

layer {
  name: "stage3_unit2_bn2"
  type: "BatchNorm"
  bottom: "stage3_unit2_conv2"
  top: "stage3_unit2_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit2_bn2"
  bottom: "stage3_unit2_conv2"
  top: "stage3_unit2_conv2"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit2_relu2"
  type: "ReLU"
  bottom: "stage3_unit2_conv2"
  top: "stage3_unit2_conv2"
  }

layer {
  name: "stage3_unit2_conv3"
  type: "Convolution"
  bottom: "stage3_unit2_conv2"
  top: "stage3_unit2_conv3"
  convolution_param { 
     num_output: 1024
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage3_unit2_bn3"
  type: "BatchNorm"
  bottom: "stage3_unit2_conv3"
  top: "stage3_unit2_conv3"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit2_bn3"
  bottom: "stage3_unit2_conv3"
  top: "stage3_unit2_conv3"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit2_plus"
  type: "Eltwise"
  bottom: "stage3_unit1_plus"
  bottom: "stage3_unit2_conv3"
  top: "stage3_unit2_plus"
  eltwise_param {
     operation: SUM
    }
  }

layer {
  name: "stage3_unit2_relu"
  type: "ReLU"
  bottom: "stage3_unit2_plus"
  top: "stage3_unit2_plus"
  }

layer {
  name: "stage3_unit3_conv1"
  type: "Convolution"
  bottom: "stage3_unit2_plus"
  top: "stage3_unit3_conv1"
  convolution_param { 
     num_output: 512
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage3_unit3_bn1"
  type: "BatchNorm"
  bottom: "stage3_unit3_conv1"
  top: "stage3_unit3_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit3_bn1"
  bottom: "stage3_unit3_conv1"
  top: "stage3_unit3_conv1"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit3_relu1"
  type: "ReLU"
  bottom: "stage3_unit3_conv1"
  top: "stage3_unit3_conv1"
  }

layer {
  name: "stage3_unit3_conv2"
  type: "Convolution"
  bottom: "stage3_unit3_conv1"
  top: "stage3_unit3_conv2"
  convolution_param { 
     num_output: 512
     kernel_size: 3
     stride: 1
     group: 32
     pad: 1
     bias_term: false
    }
  }

layer {
  name: "stage3_unit3_bn2"
  type: "BatchNorm"
  bottom: "stage3_unit3_conv2"
  top: "stage3_unit3_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit3_bn2"
  bottom: "stage3_unit3_conv2"
  top: "stage3_unit3_conv2"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit3_relu2"
  type: "ReLU"
  bottom: "stage3_unit3_conv2"
  top: "stage3_unit3_conv2"
  }

layer {
  name: "stage3_unit3_conv3"
  type: "Convolution"
  bottom: "stage3_unit3_conv2"
  top: "stage3_unit3_conv3"
  convolution_param { 
     num_output: 1024
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage3_unit3_bn3"
  type: "BatchNorm"
  bottom: "stage3_unit3_conv3"
  top: "stage3_unit3_conv3"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit3_bn3"
  bottom: "stage3_unit3_conv3"
  top: "stage3_unit3_conv3"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit3_plus"
  type: "Eltwise"
  bottom: "stage3_unit2_plus"
  bottom: "stage3_unit3_conv3"
  top: "stage3_unit3_plus"
  eltwise_param {
     operation: SUM
    }
  }

layer {
  name: "stage3_unit3_relu"
  type: "ReLU"
  bottom: "stage3_unit3_plus"
  top: "stage3_unit3_plus"
  }

layer {
  name: "stage3_unit4_conv1"
  type: "Convolution"
  bottom: "stage3_unit3_plus"
  top: "stage3_unit4_conv1"
  convolution_param { 
     num_output: 512
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage3_unit4_bn1"
  type: "BatchNorm"
  bottom: "stage3_unit4_conv1"
  top: "stage3_unit4_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit4_bn1"
  bottom: "stage3_unit4_conv1"
  top: "stage3_unit4_conv1"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit4_relu1"
  type: "ReLU"
  bottom: "stage3_unit4_conv1"
  top: "stage3_unit4_conv1"
  }

layer {
  name: "stage3_unit4_conv2"
  type: "Convolution"
  bottom: "stage3_unit4_conv1"
  top: "stage3_unit4_conv2"
  convolution_param { 
     num_output: 512
     kernel_size: 3
     stride: 1
     group: 32
     pad: 1
     bias_term: false
    }
  }

layer {
  name: "stage3_unit4_bn2"
  type: "BatchNorm"
  bottom: "stage3_unit4_conv2"
  top: "stage3_unit4_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit4_bn2"
  bottom: "stage3_unit4_conv2"
  top: "stage3_unit4_conv2"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit4_relu2"
  type: "ReLU"
  bottom: "stage3_unit4_conv2"
  top: "stage3_unit4_conv2"
  }

layer {
  name: "stage3_unit4_conv3"
  type: "Convolution"
  bottom: "stage3_unit4_conv2"
  top: "stage3_unit4_conv3"
  convolution_param { 
     num_output: 1024
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage3_unit4_bn3"
  type: "BatchNorm"
  bottom: "stage3_unit4_conv3"
  top: "stage3_unit4_conv3"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit4_bn3"
  bottom: "stage3_unit4_conv3"
  top: "stage3_unit4_conv3"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit4_plus"
  type: "Eltwise"
  bottom: "stage3_unit3_plus"
  bottom: "stage3_unit4_conv3"
  top: "stage3_unit4_plus"
  eltwise_param {
     operation: SUM
    }
  }

layer {
  name: "stage3_unit4_relu"
  type: "ReLU"
  bottom: "stage3_unit4_plus"
  top: "stage3_unit4_plus"
  }

layer {
  name: "stage3_unit5_conv1"
  type: "Convolution"
  bottom: "stage3_unit4_plus"
  top: "stage3_unit5_conv1"
  convolution_param { 
     num_output: 512
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage3_unit5_bn1"
  type: "BatchNorm"
  bottom: "stage3_unit5_conv1"
  top: "stage3_unit5_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit5_bn1"
  bottom: "stage3_unit5_conv1"
  top: "stage3_unit5_conv1"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit5_relu1"
  type: "ReLU"
  bottom: "stage3_unit5_conv1"
  top: "stage3_unit5_conv1"
  }

layer {
  name: "stage3_unit5_conv2"
  type: "Convolution"
  bottom: "stage3_unit5_conv1"
  top: "stage3_unit5_conv2"
  convolution_param { 
     num_output: 512
     kernel_size: 3
     stride: 1
     group: 32
     pad: 1
     bias_term: false
    }
  }

layer {
  name: "stage3_unit5_bn2"
  type: "BatchNorm"
  bottom: "stage3_unit5_conv2"
  top: "stage3_unit5_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit5_bn2"
  bottom: "stage3_unit5_conv2"
  top: "stage3_unit5_conv2"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit5_relu2"
  type: "ReLU"
  bottom: "stage3_unit5_conv2"
  top: "stage3_unit5_conv2"
  }

layer {
  name: "stage3_unit5_conv3"
  type: "Convolution"
  bottom: "stage3_unit5_conv2"
  top: "stage3_unit5_conv3"
  convolution_param { 
     num_output: 1024
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage3_unit5_bn3"
  type: "BatchNorm"
  bottom: "stage3_unit5_conv3"
  top: "stage3_unit5_conv3"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit5_bn3"
  bottom: "stage3_unit5_conv3"
  top: "stage3_unit5_conv3"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit5_plus"
  type: "Eltwise"
  bottom: "stage3_unit4_plus"
  bottom: "stage3_unit5_conv3"
  top: "stage3_unit5_plus"
  eltwise_param {
     operation: SUM
    }
  }

layer {
  name: "stage3_unit5_relu"
  type: "ReLU"
  bottom: "stage3_unit5_plus"
  top: "stage3_unit5_plus"
  }

layer {
  name: "stage3_unit6_conv1"
  type: "Convolution"
  bottom: "stage3_unit5_plus"
  top: "stage3_unit6_conv1"
  convolution_param { 
     num_output: 512
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage3_unit6_bn1"
  type: "BatchNorm"
  bottom: "stage3_unit6_conv1"
  top: "stage3_unit6_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit6_bn1"
  bottom: "stage3_unit6_conv1"
  top: "stage3_unit6_conv1"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit6_relu1"
  type: "ReLU"
  bottom: "stage3_unit6_conv1"
  top: "stage3_unit6_conv1"
  }

layer {
  name: "stage3_unit6_conv2"
  type: "Convolution"
  bottom: "stage3_unit6_conv1"
  top: "stage3_unit6_conv2"
  convolution_param { 
     num_output: 512
     kernel_size: 3
     stride: 1
     group: 32
     pad: 1
     bias_term: false
    }
  }

layer {
  name: "stage3_unit6_bn2"
  type: "BatchNorm"
  bottom: "stage3_unit6_conv2"
  top: "stage3_unit6_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit6_bn2"
  bottom: "stage3_unit6_conv2"
  top: "stage3_unit6_conv2"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit6_relu2"
  type: "ReLU"
  bottom: "stage3_unit6_conv2"
  top: "stage3_unit6_conv2"
  }

layer {
  name: "stage3_unit6_conv3"
  type: "Convolution"
  bottom: "stage3_unit6_conv2"
  top: "stage3_unit6_conv3"
  convolution_param { 
     num_output: 1024
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage3_unit6_bn3"
  type: "BatchNorm"
  bottom: "stage3_unit6_conv3"
  top: "stage3_unit6_conv3"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit6_bn3"
  bottom: "stage3_unit6_conv3"
  top: "stage3_unit6_conv3"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit6_plus"
  type: "Eltwise"
  bottom: "stage3_unit5_plus"
  bottom: "stage3_unit6_conv3"
  top: "stage3_unit6_plus"
  eltwise_param {
     operation: SUM
    }
  }

layer {
  name: "stage3_unit6_relu"
  type: "ReLU"
  bottom: "stage3_unit6_plus"
  top: "stage3_unit6_plus"
  }

layer {
  name: "stage3_unit7_conv1"
  type: "Convolution"
  bottom: "stage3_unit6_plus"
  top: "stage3_unit7_conv1"
  convolution_param { 
     num_output: 512
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage3_unit7_bn1"
  type: "BatchNorm"
  bottom: "stage3_unit7_conv1"
  top: "stage3_unit7_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit7_bn1"
  bottom: "stage3_unit7_conv1"
  top: "stage3_unit7_conv1"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit7_relu1"
  type: "ReLU"
  bottom: "stage3_unit7_conv1"
  top: "stage3_unit7_conv1"
  }

layer {
  name: "stage3_unit7_conv2"
  type: "Convolution"
  bottom: "stage3_unit7_conv1"
  top: "stage3_unit7_conv2"
  convolution_param { 
     num_output: 512
     kernel_size: 3
     stride: 1
     group: 32
     pad: 1
     bias_term: false
    }
  }

layer {
  name: "stage3_unit7_bn2"
  type: "BatchNorm"
  bottom: "stage3_unit7_conv2"
  top: "stage3_unit7_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit7_bn2"
  bottom: "stage3_unit7_conv2"
  top: "stage3_unit7_conv2"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit7_relu2"
  type: "ReLU"
  bottom: "stage3_unit7_conv2"
  top: "stage3_unit7_conv2"
  }

layer {
  name: "stage3_unit7_conv3"
  type: "Convolution"
  bottom: "stage3_unit7_conv2"
  top: "stage3_unit7_conv3"
  convolution_param { 
     num_output: 1024
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage3_unit7_bn3"
  type: "BatchNorm"
  bottom: "stage3_unit7_conv3"
  top: "stage3_unit7_conv3"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit7_bn3"
  bottom: "stage3_unit7_conv3"
  top: "stage3_unit7_conv3"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit7_plus"
  type: "Eltwise"
  bottom: "stage3_unit6_plus"
  bottom: "stage3_unit7_conv3"
  top: "stage3_unit7_plus"
  eltwise_param {
     operation: SUM
    }
  }

layer {
  name: "stage3_unit7_relu"
  type: "ReLU"
  bottom: "stage3_unit7_plus"
  top: "stage3_unit7_plus"
  }

layer {
  name: "stage3_unit8_conv1"
  type: "Convolution"
  bottom: "stage3_unit7_plus"
  top: "stage3_unit8_conv1"
  convolution_param { 
     num_output: 512
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage3_unit8_bn1"
  type: "BatchNorm"
  bottom: "stage3_unit8_conv1"
  top: "stage3_unit8_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit8_bn1"
  bottom: "stage3_unit8_conv1"
  top: "stage3_unit8_conv1"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit8_relu1"
  type: "ReLU"
  bottom: "stage3_unit8_conv1"
  top: "stage3_unit8_conv1"
  }

layer {
  name: "stage3_unit8_conv2"
  type: "Convolution"
  bottom: "stage3_unit8_conv1"
  top: "stage3_unit8_conv2"
  convolution_param { 
     num_output: 512
     kernel_size: 3
     stride: 1
     group: 32
     pad: 1
     bias_term: false
    }
  }

layer {
  name: "stage3_unit8_bn2"
  type: "BatchNorm"
  bottom: "stage3_unit8_conv2"
  top: "stage3_unit8_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit8_bn2"
  bottom: "stage3_unit8_conv2"
  top: "stage3_unit8_conv2"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit8_relu2"
  type: "ReLU"
  bottom: "stage3_unit8_conv2"
  top: "stage3_unit8_conv2"
  }

layer {
  name: "stage3_unit8_conv3"
  type: "Convolution"
  bottom: "stage3_unit8_conv2"
  top: "stage3_unit8_conv3"
  convolution_param { 
     num_output: 1024
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage3_unit8_bn3"
  type: "BatchNorm"
  bottom: "stage3_unit8_conv3"
  top: "stage3_unit8_conv3"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit8_bn3"
  bottom: "stage3_unit8_conv3"
  top: "stage3_unit8_conv3"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit8_plus"
  type: "Eltwise"
  bottom: "stage3_unit7_plus"
  bottom: "stage3_unit8_conv3"
  top: "stage3_unit8_plus"
  eltwise_param {
     operation: SUM
    }
  }

layer {
  name: "stage3_unit8_relu"
  type: "ReLU"
  bottom: "stage3_unit8_plus"
  top: "stage3_unit8_plus"
  }

layer {
  name: "stage3_unit9_conv1"
  type: "Convolution"
  bottom: "stage3_unit8_plus"
  top: "stage3_unit9_conv1"
  convolution_param { 
     num_output: 512
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage3_unit9_bn1"
  type: "BatchNorm"
  bottom: "stage3_unit9_conv1"
  top: "stage3_unit9_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit9_bn1"
  bottom: "stage3_unit9_conv1"
  top: "stage3_unit9_conv1"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit9_relu1"
  type: "ReLU"
  bottom: "stage3_unit9_conv1"
  top: "stage3_unit9_conv1"
  }

layer {
  name: "stage3_unit9_conv2"
  type: "Convolution"
  bottom: "stage3_unit9_conv1"
  top: "stage3_unit9_conv2"
  convolution_param { 
     num_output: 512
     kernel_size: 3
     stride: 1
     group: 32
     pad: 1
     bias_term: false
    }
  }

layer {
  name: "stage3_unit9_bn2"
  type: "BatchNorm"
  bottom: "stage3_unit9_conv2"
  top: "stage3_unit9_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit9_bn2"
  bottom: "stage3_unit9_conv2"
  top: "stage3_unit9_conv2"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit9_relu2"
  type: "ReLU"
  bottom: "stage3_unit9_conv2"
  top: "stage3_unit9_conv2"
  }

layer {
  name: "stage3_unit9_conv3"
  type: "Convolution"
  bottom: "stage3_unit9_conv2"
  top: "stage3_unit9_conv3"
  convolution_param { 
     num_output: 1024
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage3_unit9_bn3"
  type: "BatchNorm"
  bottom: "stage3_unit9_conv3"
  top: "stage3_unit9_conv3"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit9_bn3"
  bottom: "stage3_unit9_conv3"
  top: "stage3_unit9_conv3"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit9_plus"
  type: "Eltwise"
  bottom: "stage3_unit8_plus"
  bottom: "stage3_unit9_conv3"
  top: "stage3_unit9_plus"
  eltwise_param {
     operation: SUM
    }
  }

layer {
  name: "stage3_unit9_relu"
  type: "ReLU"
  bottom: "stage3_unit9_plus"
  top: "stage3_unit9_plus"
  }

layer {
  name: "stage3_unit10_conv1"
  type: "Convolution"
  bottom: "stage3_unit9_plus"
  top: "stage3_unit10_conv1"
  convolution_param { 
     num_output: 512
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage3_unit10_bn1"
  type: "BatchNorm"
  bottom: "stage3_unit10_conv1"
  top: "stage3_unit10_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit10_bn1"
  bottom: "stage3_unit10_conv1"
  top: "stage3_unit10_conv1"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit10_relu1"
  type: "ReLU"
  bottom: "stage3_unit10_conv1"
  top: "stage3_unit10_conv1"
  }

layer {
  name: "stage3_unit10_conv2"
  type: "Convolution"
  bottom: "stage3_unit10_conv1"
  top: "stage3_unit10_conv2"
  convolution_param { 
     num_output: 512
     kernel_size: 3
     stride: 1
     group: 32
     pad: 1
     bias_term: false
    }
  }

layer {
  name: "stage3_unit10_bn2"
  type: "BatchNorm"
  bottom: "stage3_unit10_conv2"
  top: "stage3_unit10_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit10_bn2"
  bottom: "stage3_unit10_conv2"
  top: "stage3_unit10_conv2"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit10_relu2"
  type: "ReLU"
  bottom: "stage3_unit10_conv2"
  top: "stage3_unit10_conv2"
  }

layer {
  name: "stage3_unit10_conv3"
  type: "Convolution"
  bottom: "stage3_unit10_conv2"
  top: "stage3_unit10_conv3"
  convolution_param { 
     num_output: 1024
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage3_unit10_bn3"
  type: "BatchNorm"
  bottom: "stage3_unit10_conv3"
  top: "stage3_unit10_conv3"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit10_bn3"
  bottom: "stage3_unit10_conv3"
  top: "stage3_unit10_conv3"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit10_plus"
  type: "Eltwise"
  bottom: "stage3_unit9_plus"
  bottom: "stage3_unit10_conv3"
  top: "stage3_unit10_plus"
  eltwise_param {
     operation: SUM
    }
  }

layer {
  name: "stage3_unit10_relu"
  type: "ReLU"
  bottom: "stage3_unit10_plus"
  top: "stage3_unit10_plus"
  }

layer {
  name: "stage3_unit11_conv1"
  type: "Convolution"
  bottom: "stage3_unit10_plus"
  top: "stage3_unit11_conv1"
  convolution_param { 
     num_output: 512
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage3_unit11_bn1"
  type: "BatchNorm"
  bottom: "stage3_unit11_conv1"
  top: "stage3_unit11_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit11_bn1"
  bottom: "stage3_unit11_conv1"
  top: "stage3_unit11_conv1"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit11_relu1"
  type: "ReLU"
  bottom: "stage3_unit11_conv1"
  top: "stage3_unit11_conv1"
  }

layer {
  name: "stage3_unit11_conv2"
  type: "Convolution"
  bottom: "stage3_unit11_conv1"
  top: "stage3_unit11_conv2"
  convolution_param { 
     num_output: 512
     kernel_size: 3
     stride: 1
     group: 32
     pad: 1
     bias_term: false
    }
  }

layer {
  name: "stage3_unit11_bn2"
  type: "BatchNorm"
  bottom: "stage3_unit11_conv2"
  top: "stage3_unit11_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit11_bn2"
  bottom: "stage3_unit11_conv2"
  top: "stage3_unit11_conv2"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit11_relu2"
  type: "ReLU"
  bottom: "stage3_unit11_conv2"
  top: "stage3_unit11_conv2"
  }

layer {
  name: "stage3_unit11_conv3"
  type: "Convolution"
  bottom: "stage3_unit11_conv2"
  top: "stage3_unit11_conv3"
  convolution_param { 
     num_output: 1024
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage3_unit11_bn3"
  type: "BatchNorm"
  bottom: "stage3_unit11_conv3"
  top: "stage3_unit11_conv3"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit11_bn3"
  bottom: "stage3_unit11_conv3"
  top: "stage3_unit11_conv3"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit11_plus"
  type: "Eltwise"
  bottom: "stage3_unit10_plus"
  bottom: "stage3_unit11_conv3"
  top: "stage3_unit11_plus"
  eltwise_param {
     operation: SUM
    }
  }

layer {
  name: "stage3_unit11_relu"
  type: "ReLU"
  bottom: "stage3_unit11_plus"
  top: "stage3_unit11_plus"
  }

layer {
  name: "stage3_unit12_conv1"
  type: "Convolution"
  bottom: "stage3_unit11_plus"
  top: "stage3_unit12_conv1"
  convolution_param { 
     num_output: 512
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage3_unit12_bn1"
  type: "BatchNorm"
  bottom: "stage3_unit12_conv1"
  top: "stage3_unit12_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit12_bn1"
  bottom: "stage3_unit12_conv1"
  top: "stage3_unit12_conv1"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit12_relu1"
  type: "ReLU"
  bottom: "stage3_unit12_conv1"
  top: "stage3_unit12_conv1"
  }

layer {
  name: "stage3_unit12_conv2"
  type: "Convolution"
  bottom: "stage3_unit12_conv1"
  top: "stage3_unit12_conv2"
  convolution_param { 
     num_output: 512
     kernel_size: 3
     stride: 1
     group: 32
     pad: 1
     bias_term: false
    }
  }

layer {
  name: "stage3_unit12_bn2"
  type: "BatchNorm"
  bottom: "stage3_unit12_conv2"
  top: "stage3_unit12_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit12_bn2"
  bottom: "stage3_unit12_conv2"
  top: "stage3_unit12_conv2"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit12_relu2"
  type: "ReLU"
  bottom: "stage3_unit12_conv2"
  top: "stage3_unit12_conv2"
  }

layer {
  name: "stage3_unit12_conv3"
  type: "Convolution"
  bottom: "stage3_unit12_conv2"
  top: "stage3_unit12_conv3"
  convolution_param { 
     num_output: 1024
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage3_unit12_bn3"
  type: "BatchNorm"
  bottom: "stage3_unit12_conv3"
  top: "stage3_unit12_conv3"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit12_bn3"
  bottom: "stage3_unit12_conv3"
  top: "stage3_unit12_conv3"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit12_plus"
  type: "Eltwise"
  bottom: "stage3_unit11_plus"
  bottom: "stage3_unit12_conv3"
  top: "stage3_unit12_plus"
  eltwise_param {
     operation: SUM
    }
  }

layer {
  name: "stage3_unit12_relu"
  type: "ReLU"
  bottom: "stage3_unit12_plus"
  top: "stage3_unit12_plus"
  }

layer {
  name: "stage3_unit13_conv1"
  type: "Convolution"
  bottom: "stage3_unit12_plus"
  top: "stage3_unit13_conv1"
  convolution_param { 
     num_output: 512
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage3_unit13_bn1"
  type: "BatchNorm"
  bottom: "stage3_unit13_conv1"
  top: "stage3_unit13_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit13_bn1"
  bottom: "stage3_unit13_conv1"
  top: "stage3_unit13_conv1"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit13_relu1"
  type: "ReLU"
  bottom: "stage3_unit13_conv1"
  top: "stage3_unit13_conv1"
  }

layer {
  name: "stage3_unit13_conv2"
  type: "Convolution"
  bottom: "stage3_unit13_conv1"
  top: "stage3_unit13_conv2"
  convolution_param { 
     num_output: 512
     kernel_size: 3
     stride: 1
     group: 32
     pad: 1
     bias_term: false
    }
  }

layer {
  name: "stage3_unit13_bn2"
  type: "BatchNorm"
  bottom: "stage3_unit13_conv2"
  top: "stage3_unit13_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit13_bn2"
  bottom: "stage3_unit13_conv2"
  top: "stage3_unit13_conv2"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit13_relu2"
  type: "ReLU"
  bottom: "stage3_unit13_conv2"
  top: "stage3_unit13_conv2"
  }

layer {
  name: "stage3_unit13_conv3"
  type: "Convolution"
  bottom: "stage3_unit13_conv2"
  top: "stage3_unit13_conv3"
  convolution_param { 
     num_output: 1024
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage3_unit13_bn3"
  type: "BatchNorm"
  bottom: "stage3_unit13_conv3"
  top: "stage3_unit13_conv3"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit13_bn3"
  bottom: "stage3_unit13_conv3"
  top: "stage3_unit13_conv3"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit13_plus"
  type: "Eltwise"
  bottom: "stage3_unit12_plus"
  bottom: "stage3_unit13_conv3"
  top: "stage3_unit13_plus"
  eltwise_param {
     operation: SUM
    }
  }

layer {
  name: "stage3_unit13_relu"
  type: "ReLU"
  bottom: "stage3_unit13_plus"
  top: "stage3_unit13_plus"
  }

layer {
  name: "stage3_unit14_conv1"
  type: "Convolution"
  bottom: "stage3_unit13_plus"
  top: "stage3_unit14_conv1"
  convolution_param { 
     num_output: 512
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage3_unit14_bn1"
  type: "BatchNorm"
  bottom: "stage3_unit14_conv1"
  top: "stage3_unit14_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit14_bn1"
  bottom: "stage3_unit14_conv1"
  top: "stage3_unit14_conv1"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit14_relu1"
  type: "ReLU"
  bottom: "stage3_unit14_conv1"
  top: "stage3_unit14_conv1"
  }

layer {
  name: "stage3_unit14_conv2"
  type: "Convolution"
  bottom: "stage3_unit14_conv1"
  top: "stage3_unit14_conv2"
  convolution_param { 
     num_output: 512
     kernel_size: 3
     stride: 1
     group: 32
     pad: 1
     bias_term: false
    }
  }

layer {
  name: "stage3_unit14_bn2"
  type: "BatchNorm"
  bottom: "stage3_unit14_conv2"
  top: "stage3_unit14_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit14_bn2"
  bottom: "stage3_unit14_conv2"
  top: "stage3_unit14_conv2"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit14_relu2"
  type: "ReLU"
  bottom: "stage3_unit14_conv2"
  top: "stage3_unit14_conv2"
  }

layer {
  name: "stage3_unit14_conv3"
  type: "Convolution"
  bottom: "stage3_unit14_conv2"
  top: "stage3_unit14_conv3"
  convolution_param { 
     num_output: 1024
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage3_unit14_bn3"
  type: "BatchNorm"
  bottom: "stage3_unit14_conv3"
  top: "stage3_unit14_conv3"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit14_bn3"
  bottom: "stage3_unit14_conv3"
  top: "stage3_unit14_conv3"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit14_plus"
  type: "Eltwise"
  bottom: "stage3_unit13_plus"
  bottom: "stage3_unit14_conv3"
  top: "stage3_unit14_plus"
  eltwise_param {
     operation: SUM
    }
  }

layer {
  name: "stage3_unit14_relu"
  type: "ReLU"
  bottom: "stage3_unit14_plus"
  top: "stage3_unit14_plus"
  }

layer {
  name: "stage3_unit15_conv1"
  type: "Convolution"
  bottom: "stage3_unit14_plus"
  top: "stage3_unit15_conv1"
  convolution_param { 
     num_output: 512
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage3_unit15_bn1"
  type: "BatchNorm"
  bottom: "stage3_unit15_conv1"
  top: "stage3_unit15_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit15_bn1"
  bottom: "stage3_unit15_conv1"
  top: "stage3_unit15_conv1"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit15_relu1"
  type: "ReLU"
  bottom: "stage3_unit15_conv1"
  top: "stage3_unit15_conv1"
  }

layer {
  name: "stage3_unit15_conv2"
  type: "Convolution"
  bottom: "stage3_unit15_conv1"
  top: "stage3_unit15_conv2"
  convolution_param { 
     num_output: 512
     kernel_size: 3
     stride: 1
     group: 32
     pad: 1
     bias_term: false
    }
  }

layer {
  name: "stage3_unit15_bn2"
  type: "BatchNorm"
  bottom: "stage3_unit15_conv2"
  top: "stage3_unit15_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit15_bn2"
  bottom: "stage3_unit15_conv2"
  top: "stage3_unit15_conv2"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit15_relu2"
  type: "ReLU"
  bottom: "stage3_unit15_conv2"
  top: "stage3_unit15_conv2"
  }

layer {
  name: "stage3_unit15_conv3"
  type: "Convolution"
  bottom: "stage3_unit15_conv2"
  top: "stage3_unit15_conv3"
  convolution_param { 
     num_output: 1024
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage3_unit15_bn3"
  type: "BatchNorm"
  bottom: "stage3_unit15_conv3"
  top: "stage3_unit15_conv3"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit15_bn3"
  bottom: "stage3_unit15_conv3"
  top: "stage3_unit15_conv3"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit15_plus"
  type: "Eltwise"
  bottom: "stage3_unit14_plus"
  bottom: "stage3_unit15_conv3"
  top: "stage3_unit15_plus"
  eltwise_param {
     operation: SUM
    }
  }

layer {
  name: "stage3_unit15_relu"
  type: "ReLU"
  bottom: "stage3_unit15_plus"
  top: "stage3_unit15_plus"
  }

layer {
  name: "stage3_unit16_conv1"
  type: "Convolution"
  bottom: "stage3_unit15_plus"
  top: "stage3_unit16_conv1"
  convolution_param { 
     num_output: 512
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage3_unit16_bn1"
  type: "BatchNorm"
  bottom: "stage3_unit16_conv1"
  top: "stage3_unit16_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit16_bn1"
  bottom: "stage3_unit16_conv1"
  top: "stage3_unit16_conv1"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit16_relu1"
  type: "ReLU"
  bottom: "stage3_unit16_conv1"
  top: "stage3_unit16_conv1"
  }

layer {
  name: "stage3_unit16_conv2"
  type: "Convolution"
  bottom: "stage3_unit16_conv1"
  top: "stage3_unit16_conv2"
  convolution_param { 
     num_output: 512
     kernel_size: 3
     stride: 1
     group: 32
     pad: 1
     bias_term: false
    }
  }

layer {
  name: "stage3_unit16_bn2"
  type: "BatchNorm"
  bottom: "stage3_unit16_conv2"
  top: "stage3_unit16_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit16_bn2"
  bottom: "stage3_unit16_conv2"
  top: "stage3_unit16_conv2"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit16_relu2"
  type: "ReLU"
  bottom: "stage3_unit16_conv2"
  top: "stage3_unit16_conv2"
  }

layer {
  name: "stage3_unit16_conv3"
  type: "Convolution"
  bottom: "stage3_unit16_conv2"
  top: "stage3_unit16_conv3"
  convolution_param { 
     num_output: 1024
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage3_unit16_bn3"
  type: "BatchNorm"
  bottom: "stage3_unit16_conv3"
  top: "stage3_unit16_conv3"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit16_bn3"
  bottom: "stage3_unit16_conv3"
  top: "stage3_unit16_conv3"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit16_plus"
  type: "Eltwise"
  bottom: "stage3_unit15_plus"
  bottom: "stage3_unit16_conv3"
  top: "stage3_unit16_plus"
  eltwise_param {
     operation: SUM
    }
  }

layer {
  name: "stage3_unit16_relu"
  type: "ReLU"
  bottom: "stage3_unit16_plus"
  top: "stage3_unit16_plus"
  }

layer {
  name: "stage3_unit17_conv1"
  type: "Convolution"
  bottom: "stage3_unit16_plus"
  top: "stage3_unit17_conv1"
  convolution_param { 
     num_output: 512
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage3_unit17_bn1"
  type: "BatchNorm"
  bottom: "stage3_unit17_conv1"
  top: "stage3_unit17_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit17_bn1"
  bottom: "stage3_unit17_conv1"
  top: "stage3_unit17_conv1"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit17_relu1"
  type: "ReLU"
  bottom: "stage3_unit17_conv1"
  top: "stage3_unit17_conv1"
  }

layer {
  name: "stage3_unit17_conv2"
  type: "Convolution"
  bottom: "stage3_unit17_conv1"
  top: "stage3_unit17_conv2"
  convolution_param { 
     num_output: 512
     kernel_size: 3
     stride: 1
     group: 32
     pad: 1
     bias_term: false
    }
  }

layer {
  name: "stage3_unit17_bn2"
  type: "BatchNorm"
  bottom: "stage3_unit17_conv2"
  top: "stage3_unit17_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit17_bn2"
  bottom: "stage3_unit17_conv2"
  top: "stage3_unit17_conv2"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit17_relu2"
  type: "ReLU"
  bottom: "stage3_unit17_conv2"
  top: "stage3_unit17_conv2"
  }

layer {
  name: "stage3_unit17_conv3"
  type: "Convolution"
  bottom: "stage3_unit17_conv2"
  top: "stage3_unit17_conv3"
  convolution_param { 
     num_output: 1024
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage3_unit17_bn3"
  type: "BatchNorm"
  bottom: "stage3_unit17_conv3"
  top: "stage3_unit17_conv3"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit17_bn3"
  bottom: "stage3_unit17_conv3"
  top: "stage3_unit17_conv3"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit17_plus"
  type: "Eltwise"
  bottom: "stage3_unit16_plus"
  bottom: "stage3_unit17_conv3"
  top: "stage3_unit17_plus"
  eltwise_param {
     operation: SUM
    }
  }

layer {
  name: "stage3_unit17_relu"
  type: "ReLU"
  bottom: "stage3_unit17_plus"
  top: "stage3_unit17_plus"
  }

layer {
  name: "stage3_unit18_conv1"
  type: "Convolution"
  bottom: "stage3_unit17_plus"
  top: "stage3_unit18_conv1"
  convolution_param { 
     num_output: 512
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage3_unit18_bn1"
  type: "BatchNorm"
  bottom: "stage3_unit18_conv1"
  top: "stage3_unit18_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit18_bn1"
  bottom: "stage3_unit18_conv1"
  top: "stage3_unit18_conv1"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit18_relu1"
  type: "ReLU"
  bottom: "stage3_unit18_conv1"
  top: "stage3_unit18_conv1"
  }

layer {
  name: "stage3_unit18_conv2"
  type: "Convolution"
  bottom: "stage3_unit18_conv1"
  top: "stage3_unit18_conv2"
  convolution_param { 
     num_output: 512
     kernel_size: 3
     stride: 1
     group: 32
     pad: 1
     bias_term: false
    }
  }

layer {
  name: "stage3_unit18_bn2"
  type: "BatchNorm"
  bottom: "stage3_unit18_conv2"
  top: "stage3_unit18_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit18_bn2"
  bottom: "stage3_unit18_conv2"
  top: "stage3_unit18_conv2"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit18_relu2"
  type: "ReLU"
  bottom: "stage3_unit18_conv2"
  top: "stage3_unit18_conv2"
  }

layer {
  name: "stage3_unit18_conv3"
  type: "Convolution"
  bottom: "stage3_unit18_conv2"
  top: "stage3_unit18_conv3"
  convolution_param { 
     num_output: 1024
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage3_unit18_bn3"
  type: "BatchNorm"
  bottom: "stage3_unit18_conv3"
  top: "stage3_unit18_conv3"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit18_bn3"
  bottom: "stage3_unit18_conv3"
  top: "stage3_unit18_conv3"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit18_plus"
  type: "Eltwise"
  bottom: "stage3_unit17_plus"
  bottom: "stage3_unit18_conv3"
  top: "stage3_unit18_plus"
  eltwise_param {
     operation: SUM
    }
  }

layer {
  name: "stage3_unit18_relu"
  type: "ReLU"
  bottom: "stage3_unit18_plus"
  top: "stage3_unit18_plus"
  }

layer {
  name: "stage3_unit19_conv1"
  type: "Convolution"
  bottom: "stage3_unit18_plus"
  top: "stage3_unit19_conv1"
  convolution_param { 
     num_output: 512
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage3_unit19_bn1"
  type: "BatchNorm"
  bottom: "stage3_unit19_conv1"
  top: "stage3_unit19_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit19_bn1"
  bottom: "stage3_unit19_conv1"
  top: "stage3_unit19_conv1"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit19_relu1"
  type: "ReLU"
  bottom: "stage3_unit19_conv1"
  top: "stage3_unit19_conv1"
  }

layer {
  name: "stage3_unit19_conv2"
  type: "Convolution"
  bottom: "stage3_unit19_conv1"
  top: "stage3_unit19_conv2"
  convolution_param { 
     num_output: 512
     kernel_size: 3
     stride: 1
     group: 32
     pad: 1
     bias_term: false
    }
  }

layer {
  name: "stage3_unit19_bn2"
  type: "BatchNorm"
  bottom: "stage3_unit19_conv2"
  top: "stage3_unit19_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit19_bn2"
  bottom: "stage3_unit19_conv2"
  top: "stage3_unit19_conv2"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit19_relu2"
  type: "ReLU"
  bottom: "stage3_unit19_conv2"
  top: "stage3_unit19_conv2"
  }

layer {
  name: "stage3_unit19_conv3"
  type: "Convolution"
  bottom: "stage3_unit19_conv2"
  top: "stage3_unit19_conv3"
  convolution_param { 
     num_output: 1024
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage3_unit19_bn3"
  type: "BatchNorm"
  bottom: "stage3_unit19_conv3"
  top: "stage3_unit19_conv3"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit19_bn3"
  bottom: "stage3_unit19_conv3"
  top: "stage3_unit19_conv3"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit19_plus"
  type: "Eltwise"
  bottom: "stage3_unit18_plus"
  bottom: "stage3_unit19_conv3"
  top: "stage3_unit19_plus"
  eltwise_param {
     operation: SUM
    }
  }

layer {
  name: "stage3_unit19_relu"
  type: "ReLU"
  bottom: "stage3_unit19_plus"
  top: "stage3_unit19_plus"
  }

layer {
  name: "stage3_unit20_conv1"
  type: "Convolution"
  bottom: "stage3_unit19_plus"
  top: "stage3_unit20_conv1"
  convolution_param { 
     num_output: 512
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage3_unit20_bn1"
  type: "BatchNorm"
  bottom: "stage3_unit20_conv1"
  top: "stage3_unit20_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit20_bn1"
  bottom: "stage3_unit20_conv1"
  top: "stage3_unit20_conv1"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit20_relu1"
  type: "ReLU"
  bottom: "stage3_unit20_conv1"
  top: "stage3_unit20_conv1"
  }

layer {
  name: "stage3_unit20_conv2"
  type: "Convolution"
  bottom: "stage3_unit20_conv1"
  top: "stage3_unit20_conv2"
  convolution_param { 
     num_output: 512
     kernel_size: 3
     stride: 1
     group: 32
     pad: 1
     bias_term: false
    }
  }

layer {
  name: "stage3_unit20_bn2"
  type: "BatchNorm"
  bottom: "stage3_unit20_conv2"
  top: "stage3_unit20_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit20_bn2"
  bottom: "stage3_unit20_conv2"
  top: "stage3_unit20_conv2"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit20_relu2"
  type: "ReLU"
  bottom: "stage3_unit20_conv2"
  top: "stage3_unit20_conv2"
  }

layer {
  name: "stage3_unit20_conv3"
  type: "Convolution"
  bottom: "stage3_unit20_conv2"
  top: "stage3_unit20_conv3"
  convolution_param { 
     num_output: 1024
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage3_unit20_bn3"
  type: "BatchNorm"
  bottom: "stage3_unit20_conv3"
  top: "stage3_unit20_conv3"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit20_bn3"
  bottom: "stage3_unit20_conv3"
  top: "stage3_unit20_conv3"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit20_plus"
  type: "Eltwise"
  bottom: "stage3_unit19_plus"
  bottom: "stage3_unit20_conv3"
  top: "stage3_unit20_plus"
  eltwise_param {
     operation: SUM
    }
  }

layer {
  name: "stage3_unit20_relu"
  type: "ReLU"
  bottom: "stage3_unit20_plus"
  top: "stage3_unit20_plus"
  }

layer {
  name: "stage3_unit21_conv1"
  type: "Convolution"
  bottom: "stage3_unit20_plus"
  top: "stage3_unit21_conv1"
  convolution_param { 
     num_output: 512
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage3_unit21_bn1"
  type: "BatchNorm"
  bottom: "stage3_unit21_conv1"
  top: "stage3_unit21_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit21_bn1"
  bottom: "stage3_unit21_conv1"
  top: "stage3_unit21_conv1"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit21_relu1"
  type: "ReLU"
  bottom: "stage3_unit21_conv1"
  top: "stage3_unit21_conv1"
  }

layer {
  name: "stage3_unit21_conv2"
  type: "Convolution"
  bottom: "stage3_unit21_conv1"
  top: "stage3_unit21_conv2"
  convolution_param { 
     num_output: 512
     kernel_size: 3
     stride: 1
     group: 32
     pad: 1
     bias_term: false
    }
  }

layer {
  name: "stage3_unit21_bn2"
  type: "BatchNorm"
  bottom: "stage3_unit21_conv2"
  top: "stage3_unit21_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit21_bn2"
  bottom: "stage3_unit21_conv2"
  top: "stage3_unit21_conv2"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit21_relu2"
  type: "ReLU"
  bottom: "stage3_unit21_conv2"
  top: "stage3_unit21_conv2"
  }

layer {
  name: "stage3_unit21_conv3"
  type: "Convolution"
  bottom: "stage3_unit21_conv2"
  top: "stage3_unit21_conv3"
  convolution_param { 
     num_output: 1024
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage3_unit21_bn3"
  type: "BatchNorm"
  bottom: "stage3_unit21_conv3"
  top: "stage3_unit21_conv3"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit21_bn3"
  bottom: "stage3_unit21_conv3"
  top: "stage3_unit21_conv3"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit21_plus"
  type: "Eltwise"
  bottom: "stage3_unit20_plus"
  bottom: "stage3_unit21_conv3"
  top: "stage3_unit21_plus"
  eltwise_param {
     operation: SUM
    }
  }

layer {
  name: "stage3_unit21_relu"
  type: "ReLU"
  bottom: "stage3_unit21_plus"
  top: "stage3_unit21_plus"
  }

layer {
  name: "stage3_unit22_conv1"
  type: "Convolution"
  bottom: "stage3_unit21_plus"
  top: "stage3_unit22_conv1"
  convolution_param { 
     num_output: 512
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage3_unit22_bn1"
  type: "BatchNorm"
  bottom: "stage3_unit22_conv1"
  top: "stage3_unit22_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit22_bn1"
  bottom: "stage3_unit22_conv1"
  top: "stage3_unit22_conv1"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit22_relu1"
  type: "ReLU"
  bottom: "stage3_unit22_conv1"
  top: "stage3_unit22_conv1"
  }

layer {
  name: "stage3_unit22_conv2"
  type: "Convolution"
  bottom: "stage3_unit22_conv1"
  top: "stage3_unit22_conv2"
  convolution_param { 
     num_output: 512
     kernel_size: 3
     stride: 1
     group: 32
     pad: 1
     bias_term: false
    }
  }

layer {
  name: "stage3_unit22_bn2"
  type: "BatchNorm"
  bottom: "stage3_unit22_conv2"
  top: "stage3_unit22_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit22_bn2"
  bottom: "stage3_unit22_conv2"
  top: "stage3_unit22_conv2"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit22_relu2"
  type: "ReLU"
  bottom: "stage3_unit22_conv2"
  top: "stage3_unit22_conv2"
  }

layer {
  name: "stage3_unit22_conv3"
  type: "Convolution"
  bottom: "stage3_unit22_conv2"
  top: "stage3_unit22_conv3"
  convolution_param { 
     num_output: 1024
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage3_unit22_bn3"
  type: "BatchNorm"
  bottom: "stage3_unit22_conv3"
  top: "stage3_unit22_conv3"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit22_bn3"
  bottom: "stage3_unit22_conv3"
  top: "stage3_unit22_conv3"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit22_plus"
  type: "Eltwise"
  bottom: "stage3_unit21_plus"
  bottom: "stage3_unit22_conv3"
  top: "stage3_unit22_plus"
  eltwise_param {
     operation: SUM
    }
  }

layer {
  name: "stage3_unit22_relu"
  type: "ReLU"
  bottom: "stage3_unit22_plus"
  top: "stage3_unit22_plus"
  }

layer {
  name: "stage3_unit23_conv1"
  type: "Convolution"
  bottom: "stage3_unit22_plus"
  top: "stage3_unit23_conv1"
  convolution_param { 
     num_output: 512
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage3_unit23_bn1"
  type: "BatchNorm"
  bottom: "stage3_unit23_conv1"
  top: "stage3_unit23_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit23_bn1"
  bottom: "stage3_unit23_conv1"
  top: "stage3_unit23_conv1"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit23_relu1"
  type: "ReLU"
  bottom: "stage3_unit23_conv1"
  top: "stage3_unit23_conv1"
  }

layer {
  name: "stage3_unit23_conv2"
  type: "Convolution"
  bottom: "stage3_unit23_conv1"
  top: "stage3_unit23_conv2"
  convolution_param { 
     num_output: 512
     kernel_size: 3
     stride: 1
     group: 32
     pad: 1
     bias_term: false
    }
  }

layer {
  name: "stage3_unit23_bn2"
  type: "BatchNorm"
  bottom: "stage3_unit23_conv2"
  top: "stage3_unit23_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit23_bn2"
  bottom: "stage3_unit23_conv2"
  top: "stage3_unit23_conv2"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit23_relu2"
  type: "ReLU"
  bottom: "stage3_unit23_conv2"
  top: "stage3_unit23_conv2"
  }

layer {
  name: "stage3_unit23_conv3"
  type: "Convolution"
  bottom: "stage3_unit23_conv2"
  top: "stage3_unit23_conv3"
  convolution_param { 
     num_output: 1024
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage3_unit23_bn3"
  type: "BatchNorm"
  bottom: "stage3_unit23_conv3"
  top: "stage3_unit23_conv3"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage3_unit23_bn3"
  bottom: "stage3_unit23_conv3"
  top: "stage3_unit23_conv3"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage3_unit23_plus"
  type: "Eltwise"
  bottom: "stage3_unit22_plus"
  bottom: "stage3_unit23_conv3"
  top: "stage3_unit23_plus"
  eltwise_param {
     operation: SUM
    }
  }

layer {
  name: "stage3_unit23_relu"
  type: "ReLU"
  bottom: "stage3_unit23_plus"
  top: "stage3_unit23_plus"
  }

layer {
  name: "stage4_unit1_conv1"
  type: "Convolution"
  bottom: "stage3_unit23_plus"
  top: "stage4_unit1_conv1"
  convolution_param { 
     num_output: 1024
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage4_unit1_bn1"
  type: "BatchNorm"
  bottom: "stage4_unit1_conv1"
  top: "stage4_unit1_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage4_unit1_bn1"
  bottom: "stage4_unit1_conv1"
  top: "stage4_unit1_conv1"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage4_unit1_relu1"
  type: "ReLU"
  bottom: "stage4_unit1_conv1"
  top: "stage4_unit1_conv1"
  }

layer {
  name: "stage4_unit1_conv2"
  type: "Convolution"
  bottom: "stage4_unit1_conv1"
  top: "stage4_unit1_conv2"
  convolution_param { 
     num_output: 1024
     kernel_size: 3
     stride: 2
     group: 32
     pad: 1
     bias_term: false
    }
  }

layer {
  name: "stage4_unit1_bn2"
  type: "BatchNorm"
  bottom: "stage4_unit1_conv2"
  top: "stage4_unit1_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage4_unit1_bn2"
  bottom: "stage4_unit1_conv2"
  top: "stage4_unit1_conv2"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage4_unit1_relu2"
  type: "ReLU"
  bottom: "stage4_unit1_conv2"
  top: "stage4_unit1_conv2"
  }

layer {
  name: "stage4_unit1_conv3"
  type: "Convolution"
  bottom: "stage4_unit1_conv2"
  top: "stage4_unit1_conv3"
  convolution_param { 
     num_output: 2048
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage4_unit1_bn3"
  type: "BatchNorm"
  bottom: "stage4_unit1_conv3"
  top: "stage4_unit1_conv3"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage4_unit1_bn3"
  bottom: "stage4_unit1_conv3"
  top: "stage4_unit1_conv3"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage4_unit1_sc"
  type: "Convolution"
  bottom: "stage3_unit23_plus"
  top: "stage4_unit1_sc"
  convolution_param { 
     num_output: 2048
     kernel_size: 1
     stride: 2
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage4_unit1_sc_bn"
  type: "BatchNorm"
  bottom: "stage4_unit1_sc"
  top: "stage4_unit1_sc"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage4_unit1_sc_bn"
  bottom: "stage4_unit1_sc"
  top: "stage4_unit1_sc"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage4_unit1_plus"
  type: "Eltwise"
  bottom: "stage4_unit1_sc"
  bottom: "stage4_unit1_conv3"
  top: "stage4_unit1_plus"
  eltwise_param {
     operation: SUM
    }
  }

layer {
  name: "stage4_unit1_relu"
  type: "ReLU"
  bottom: "stage4_unit1_plus"
  top: "stage4_unit1_plus"
  }

layer {
  name: "stage4_unit2_conv1"
  type: "Convolution"
  bottom: "stage4_unit1_plus"
  top: "stage4_unit2_conv1"
  convolution_param { 
     num_output: 1024
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage4_unit2_bn1"
  type: "BatchNorm"
  bottom: "stage4_unit2_conv1"
  top: "stage4_unit2_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage4_unit2_bn1"
  bottom: "stage4_unit2_conv1"
  top: "stage4_unit2_conv1"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage4_unit2_relu1"
  type: "ReLU"
  bottom: "stage4_unit2_conv1"
  top: "stage4_unit2_conv1"
  }

layer {
  name: "stage4_unit2_conv2"
  type: "Convolution"
  bottom: "stage4_unit2_conv1"
  top: "stage4_unit2_conv2"
  convolution_param { 
     num_output: 1024
     kernel_size: 3
     stride: 1
     group: 32
     pad: 1
     bias_term: false
    }
  }

layer {
  name: "stage4_unit2_bn2"
  type: "BatchNorm"
  bottom: "stage4_unit2_conv2"
  top: "stage4_unit2_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage4_unit2_bn2"
  bottom: "stage4_unit2_conv2"
  top: "stage4_unit2_conv2"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage4_unit2_relu2"
  type: "ReLU"
  bottom: "stage4_unit2_conv2"
  top: "stage4_unit2_conv2"
  }

layer {
  name: "stage4_unit2_conv3"
  type: "Convolution"
  bottom: "stage4_unit2_conv2"
  top: "stage4_unit2_conv3"
  convolution_param { 
     num_output: 2048
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage4_unit2_bn3"
  type: "BatchNorm"
  bottom: "stage4_unit2_conv3"
  top: "stage4_unit2_conv3"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage4_unit2_bn3"
  bottom: "stage4_unit2_conv3"
  top: "stage4_unit2_conv3"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage4_unit2_plus"
  type: "Eltwise"
  bottom: "stage4_unit1_plus"
  bottom: "stage4_unit2_conv3"
  top: "stage4_unit2_plus"
  eltwise_param {
     operation: SUM
    }
  }

layer {
  name: "stage4_unit2_relu"
  type: "ReLU"
  bottom: "stage4_unit2_plus"
  top: "stage4_unit2_plus"
  }

layer {
  name: "stage4_unit3_conv1"
  type: "Convolution"
  bottom: "stage4_unit2_plus"
  top: "stage4_unit3_conv1"
  convolution_param { 
     num_output: 1024
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage4_unit3_bn1"
  type: "BatchNorm"
  bottom: "stage4_unit3_conv1"
  top: "stage4_unit3_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage4_unit3_bn1"
  bottom: "stage4_unit3_conv1"
  top: "stage4_unit3_conv1"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage4_unit3_relu1"
  type: "ReLU"
  bottom: "stage4_unit3_conv1"
  top: "stage4_unit3_conv1"
  }

layer {
  name: "stage4_unit3_conv2"
  type: "Convolution"
  bottom: "stage4_unit3_conv1"
  top: "stage4_unit3_conv2"
  convolution_param { 
     num_output: 1024
     kernel_size: 3
     stride: 1
     group: 32
     pad: 1
     bias_term: false
    }
  }

layer {
  name: "stage4_unit3_bn2"
  type: "BatchNorm"
  bottom: "stage4_unit3_conv2"
  top: "stage4_unit3_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage4_unit3_bn2"
  bottom: "stage4_unit3_conv2"
  top: "stage4_unit3_conv2"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage4_unit3_relu2"
  type: "ReLU"
  bottom: "stage4_unit3_conv2"
  top: "stage4_unit3_conv2"
  }

layer {
  name: "stage4_unit3_conv3"
  type: "Convolution"
  bottom: "stage4_unit3_conv2"
  top: "stage4_unit3_conv3"
  convolution_param { 
     num_output: 2048
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: false
    }
  }

layer {
  name: "stage4_unit3_bn3"
  type: "BatchNorm"
  bottom: "stage4_unit3_conv3"
  top: "stage4_unit3_conv3"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
    }
  }

layer {
  name: "scale_stage4_unit3_bn3"
  bottom: "stage4_unit3_conv3"
  top: "stage4_unit3_conv3"
  type: "Scale"
  scale_param {
        bias_term: true
    }
  }

layer {
  name: "stage4_unit3_plus"
  type: "Eltwise"
  bottom: "stage4_unit2_plus"
  bottom: "stage4_unit3_conv3"
  top: "stage4_unit3_plus"
  eltwise_param {
     operation: SUM
    }
  }

layer {
  name: "stage4_unit3_relu"
  type: "ReLU"
  bottom: "stage4_unit3_plus"
  top: "stage4_unit3_plus"
  }

layer {
  name: "pool1"
  type: "Pooling"
  bottom: "stage4_unit3_plus"
  top: "pool1"
  pooling_param {
     global_pooling : true
     pool: AVE
    }
  }

layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "fc1"
  param {
    lr_mult: 1
    decay_mult: 1
    }
  param {
    lr_mult: 2
    decay_mult: 0
    }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "xavier"
      }
    bias_filler {
      type: "constant"
      value: 0
      }
    }
  }

layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc1"
  top: "prob"
  }

